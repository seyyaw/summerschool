{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyyaw/summerschool/blob/main/NLP_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09054155",
      "metadata": {
        "id": "09054155",
        "outputId": "4787e5f1-cd3e-44fb-ae6e-70da76c2b454"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style> \n",
              "table {display: block;} \n",
              "td {\n",
              "  font-size: 18px\n",
              "}\n",
              ".rendered_html { font-size: 28px; }\n",
              "*{ line-height: 200%; }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<style>\n",
        "table {display: block;}\n",
        "td {\n",
        "  font-size: 18px\n",
        "}\n",
        ".rendered_html { font-size: 28px; }\n",
        "*{ line-height: 200%; }\n",
        "</style>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0299f05d",
      "metadata": {
        "id": "0299f05d"
      },
      "source": [
        "# Summer School for Women in AI and Data Sceince\n",
        "---\n",
        "---\n",
        "# <span style=\"color:blue\">Natural Language Processing</span>\n",
        " ---\n",
        "## -  <span style=\"color:red\">Seid Muhie Yimam  - UHH, HCDS</span>\n",
        "## -  <span style=\"color:red\">Hellina Hailu Negatu -  University of Berkeley</span>\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4861f7f",
      "metadata": {
        "id": "d4861f7f"
      },
      "source": [
        "# Content\n",
        "1. Further text processing\n",
        "1. NLP applications, ML, and Feature engineering\n",
        "1. Text representation\n",
        "   1. One hot embedding/bag of words\n",
        "   1. TFIDF\n",
        "   1. Word2vec\n",
        "   1. Transformer, BERT and RoBERTa\n",
        "1. Large Language Models\n",
        "1. Resources and repositories"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "590a1b51",
      "metadata": {
        "id": "590a1b51"
      },
      "source": [
        "# Transformers, BERT and RoBERTa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edc5e1a",
      "metadata": {
        "id": "9edc5e1a"
      },
      "source": [
        "# Transformers\n",
        "Transformers are a recent advancement in machine learning known for their exceptional ability to manage context, which allows them to generate coherent text."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8616190",
      "metadata": {
        "id": "f8616190"
      },
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GIVM8Wat6Vq8W7Eff-f_5w.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be327152",
      "metadata": {
        "id": "be327152"
      },
      "source": [
        "At the basic, transformers help predicting the next word based on the previous contex\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1aA6C837tO84KrwCzfmO8w.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea2d4af",
      "metadata": {
        "id": "aea2d4af"
      },
      "source": [
        "Command: Write a story.\n",
        "- Response: Once\n",
        "\n",
        "Next command: Write a story. Once\n",
        "\n",
        "- Response: upon\n",
        "\n",
        "Next command: Write a story. Once upon\n",
        "- Response: a\n",
        "\n",
        "Next command: Write a story. Once upon a\n",
        "- Response: time\n",
        "\n",
        "Next command: Write a story. Once upon a time\n",
        "- Response: there"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3732592d",
      "metadata": {
        "id": "3732592d"
      },
      "source": [
        "# Transformer components\n",
        "    Tokenization\n",
        "    Embedding\n",
        "    Positional encoding\n",
        "    Transformer block (several of these)\n",
        "    Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3845efc0",
      "metadata": {
        "id": "3845efc0"
      },
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EKNbZWqHGpq7LeC5k6auRA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d97b80d1",
      "metadata": {
        "id": "d97b80d1"
      },
      "source": [
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zTFLvNHbbRlAMZBqPkalkA.png)\n",
        "Tokenization is the process of converting text into a series of known tokens, including words, prefixes, suffixes, and punctuation marks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f10b9cd",
      "metadata": {
        "id": "9f10b9cd"
      },
      "source": [
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VsatPWp0Q2mcX5pbxijjfQ.png)\n",
        "Embedding converts tokenized input into numerical vectors, where similar texts yield similar vector values and dissimilar texts differ numerically."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f5768a4",
      "metadata": {
        "id": "4f5768a4"
      },
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tY6CBYjfMDc2b-4PoZGiHA.png)\n",
        "Positional encoding adds a positional vector to each word, in order to keep track of the positions of the words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f6424a0",
      "metadata": {
        "id": "6f6424a0"
      },
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lf2bhrFFS4y--WmgBmAyjQ.png)\n",
        "A transformer block consists of an attention component and a feedforward network, crucial for contextualizing and processing sequence data in models predicting the next word in a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1c9683",
      "metadata": {
        "id": "dc1c9683"
      },
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rql7F3gVwcDIAwLbWKV8kQ.png)\n",
        "The attention mechanism helps resolve contextual ambiguities in language models by adjusting how words relate based on their surrounding words. It differentiates meanings like distinguishing \"bank\" in **Money in the bank** from \"bank\" in **The bank of the river.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2567d3a",
      "metadata": {
        "id": "a2567d3a"
      },
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tW3hIJWaKuZ9bIMIiqudZA.png)\n",
        "The softmax layer in a transformer converts scores into probabilities for each word, ensuring they sum to one. This step prioritizes words with higher scores by giving them greater likelihoods of being selected as the next word. By sampling from these probabilities, the transformer determines the most likely next word, such as \"once\" from options like \"Once,\" \"Somewhere,\" and \"There.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dd7f2ee",
      "metadata": {
        "id": "1dd7f2ee"
      },
      "source": [
        "# Finetuning Transformer models\n",
        "Fine-tuning is the process of training a pre-trained transformer model on a specific dataset to enhance its ability to perform particular tasks, like answering questions or functioning as a chatbot. This additional training phase helps the model adjust from broad, general knowledge to a more focused application, improving its responses and relevance. By fine-tuning, transformers can overcome biases toward their initial training and better adapt to new, task-specific data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a73dc98",
      "metadata": {
        "id": "9a73dc98"
      },
      "source": [
        "# Simpe Transformer <span style=\"color:blue\">Hands-on</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf9baae",
      "metadata": {
        "id": "8cf9baae",
        "outputId": "9bdeae89-b5fa-4329-c1d7-d483d5096a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/yimam/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
            "Collecting torchvision\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/b5/14/c05da13c98f528ba5fd99897320a7684df5dd136ec6faa6a5766f25e4a7e/torchvision-0.18.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: numpy in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
            "Collecting torch\n",
            "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/ad/08/c5e41eb22323db4a52260607598a207a2e1918916ae8201aa7a8ae005fcd/torch-2.3.0-cp311-none-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torch-2.3.0-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from torchvision) (10.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torchvision-0.18.0-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
            "\u001b[?25hDownloading torch-2.3.0-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hInstalling collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1\n",
            "    Uninstalling torch-2.2.1:\n",
            "      Successfully uninstalled torch-2.2.1\n",
            "Successfully installed torch-2.3.0 torchvision-0.18.0\n"
          ]
        }
      ],
      "source": [
        "#Installation\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97237c1f",
      "metadata": {
        "id": "97237c1f",
        "outputId": "a4e635d6-726f-4747-f7b9-1a2e8be24b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/yimam/anaconda3/lib/python3.11/site-packages (4.36.0)\n",
            "Requirement already satisfied: filelock in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f80e073",
      "metadata": {
        "id": "6f80e073",
        "outputId": "33cc08aa-2815-4ecb-b5f8-5b3bad95f589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorboardx\n",
            "  Obtaining dependency information for tensorboardx from https://files.pythonhosted.org/packages/44/71/f3e7c9b2ab67e28c572ab4e9d5fa3499e0d252650f96d8a3a03e26677f53/tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /Users/yimam/anaconda3/lib/python3.11/site-packages (from tensorboardx) (1.24.3)\n",
            "Requirement already satisfied: packaging in /Users/yimam/anaconda3/lib/python3.11/site-packages (from tensorboardx) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from tensorboardx) (5.26.1)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m701.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa01ad0",
      "metadata": {
        "id": "afa01ad0",
        "outputId": "76e2a407-4b41-4320-f7bc-3877b39fd38e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting simpletransformers\n",
            "  Obtaining dependency information for simpletransformers from https://files.pythonhosted.org/packages/73/6b/cc77e202e0dad657ff249f68402ab27f10312649f3488c94e9177c868849/simpletransformers-0.70.0-py3-none-any.whl.metadata\n",
            "  Downloading simpletransformers-0.70.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m363.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: requests in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (4.65.0)\n",
            "Requirement already satisfied: regex in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2022.7.9)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (4.36.0)\n",
            "Requirement already satisfied: datasets in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2.12.0)\n",
            "Requirement already satisfied: scipy in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (1.11.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (1.3.0)\n",
            "Collecting seqeval (from simpletransformers)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tensorboard (from simpletransformers)\n",
            "  Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/3a/d0/b97889ffa769e2d1fdebb632084d5e8b53fc299d43a537acee7ec0c021a3/tensorboard-2.16.2-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tensorboardx in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2.6.2.2)\n",
            "Requirement already satisfied: pandas in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2.0.3)\n",
            "Requirement already satisfied: tokenizers in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (0.15.2)\n",
            "Collecting wandb>=0.10.32 (from simpletransformers)\n",
            "  Obtaining dependency information for wandb>=0.10.32 from https://files.pythonhosted.org/packages/8b/8d/bb05a4ecdeac6b2256d98ac10bae8723af5d7a8c1a4c2384b3ae0f80370e/wandb-0.16.6-py3-none-any.whl.metadata\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting streamlit (from simpletransformers)\n",
            "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/88/34/0751fd391fe90c8a90e70ef267080e0d461a2bf00c9e84c5a39d3389470d/streamlit-1.34.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading streamlit-1.34.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: sentencepiece in /Users/yimam/anaconda3/lib/python3.11/site-packages (from simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: filelock in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (0.22.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (6.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (0.3.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (8.0.4)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Obtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl.metadata\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/e3/6a/3c828b86776e0d6dd3bc2b70d5f3bd8a358ed1b6831782ccc74d581de08e/sentry_sdk-2.0.1-py2.py3-none-any.whl.metadata\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Obtaining dependency information for docker-pycreds>=0.4.0 from https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting setproctitle (from wandb>=0.10.32->simpletransformers)\n",
            "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/c9/17/7f9d5ddf4cfc4386e74565ccf63b8381396336e4629bb165b52b803ceddb/setproctitle-1.3.3-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading setproctitle-1.3.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /Users/yimam/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (68.0.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
            "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb>=0.10.32->simpletransformers)\n",
            "  Obtaining dependency information for protobuf!=4.21.0,<5,>=3.19.0 from https://files.pythonhosted.org/packages/f3/bf/26deba06a4c910a85f78245cac7698f67cedd7efe00d04f6b3e1b3506a59/protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
            "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (2023.11.17)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (11.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /Users/yimam/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /Users/yimam/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /Users/yimam/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (3.8.5)\n",
            "Requirement already satisfied: responses<0.19 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (0.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from pandas->simpletransformers) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from pandas->simpletransformers) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from scikit-learn->simpletransformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from scikit-learn->simpletransformers) (2.2.0)\n",
            "Collecting altair<6,>=4.0 (from streamlit->simpletransformers)\n",
            "  Obtaining dependency information for altair<6,>=4.0 from https://files.pythonhosted.org/packages/46/30/2118537233fa72c1d91a81f5908a7e843a6601ccc68b76838ebc4951505f/altair-5.3.0-py3-none-any.whl.metadata\n",
            "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting blinker<2,>=1.0.0 (from streamlit->simpletransformers)\n",
            "  Obtaining dependency information for blinker<2,>=1.0.0 from https://files.pythonhosted.org/packages/b8/a8/e2c40dc86dfc88fea7b627123e0a8e33ad1978af1f521629ec0f9a6e5da8/blinker-1.8.1-py3-none-any.whl.metadata\n",
            "  Downloading blinker-1.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cachetools<6,>=4.0 (from streamlit->simpletransformers)\n",
            "  Obtaining dependency information for cachetools<6,>=4.0 from https://files.pythonhosted.org/packages/fb/2b/a64c2d25a37aeb921fddb929111413049fc5f8b9a4c1aefaffaafe768d54/cachetools-5.3.3-py3-none-any.whl.metadata\n",
            "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (10.0.1)\n",
            "Collecting rich<14,>=10.14.0 (from streamlit->simpletransformers)\n",
            "  Obtaining dependency information for rich<14,>=10.14.0 from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
            "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (8.2.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (4.10.0)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n",
            "  Obtaining dependency information for pydeck<1,>=0.8.0b4 from https://files.pythonhosted.org/packages/8d/37/05e6f244f73829787ca34f0c791665be43447d5b7b230ecd65ad6df3f103/pydeck-0.9.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading pydeck-0.9.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (6.3.2)\n",
            "Collecting absl-py>=0.4 (from tensorboard->simpletransformers)\n",
            "  Obtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->simpletransformers)\n",
            "  Obtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/a4/83/c3a8480f170894c132ef00450ab11ed5c86ae047c54fd7b7faf6a53475c7/grpcio-1.63.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading grpcio-1.63.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from tensorboard->simpletransformers) (3.4.1)\n",
            "Requirement already satisfied: six>1.9 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from tensorboard->simpletransformers) (1.16.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->simpletransformers)\n",
            "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from tensorboard->simpletransformers) (2.2.3)\n",
            "Requirement already satisfied: jinja2 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.21.1)\n",
            "Requirement already satisfied: toolz in /Users/yimam/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (1.2.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
            "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
            "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.15.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers)\n",
            "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
            "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/yimam/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.0)\n",
            "Downloading simpletransformers-0.70.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading blinker-1.8.1-py3-none-any.whl (9.5 kB)\n",
            "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
            "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.63.0-cp311-cp311-macosx_10_9_universal2.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
            "\u001b[?25hUsing cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
            "Downloading pydeck-0.9.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Downloading setproctitle-1.3.3-cp311-cp311-macosx_10_9_universal2.whl (16 kB)\n",
            "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=b2ce4107ff1fcb733b8a71dbe09e561081768e58edd214d18679ec92076702ef\n",
            "  Stored in directory: /Users/yimam/Library/Caches/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tensorboard-data-server, smmap, setproctitle, sentry-sdk, protobuf, grpcio, docker-pycreds, cachetools, blinker, absl-py, tensorboard, rich, pydeck, gitdb, seqeval, GitPython, wandb, altair, streamlit, simpletransformers\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.26.1\n",
            "    Uninstalling protobuf-5.26.1:\n",
            "      Successfully uninstalled protobuf-5.26.1\n",
            "Successfully installed GitPython-3.1.43 absl-py-2.1.0 altair-5.3.0 blinker-1.8.1 cachetools-5.3.3 docker-pycreds-0.4.0 gitdb-4.0.11 grpcio-1.63.0 protobuf-4.25.3 pydeck-0.9.0 rich-13.7.1 sentry-sdk-2.0.1 seqeval-1.2.2 setproctitle-1.3.3 simpletransformers-0.70.0 smmap-5.0.1 streamlit-1.34.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 wandb-0.16.6\n"
          ]
        }
      ],
      "source": [
        "!pip install simpletransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4fed419",
      "metadata": {
        "id": "a4fed419",
        "outputId": "0eb624f7-2262-4aa9-a159-b706a623c9b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% [..................................................] 166373201 / 166373201"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'yelp_review_polarity_csv.tgz'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wget\n",
        "wget.download(\"https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a217fa3",
      "metadata": {
        "id": "3a217fa3",
        "outputId": "be370c0c-c1c6-48dd-d412-dddbe58e44a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-05 21:17:09--  https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.26.22, 52.217.230.96, 52.216.10.93, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.26.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166373201 (159M) [application/x-tar]\n",
            "Saving to: ‘data/data.tgz’\n",
            "\n",
            "data/data.tgz       100%[===================>] 158,67M  1,03MB/s    in 3m 2s   \n",
            "\n",
            "2024-05-05 21:20:11 (895 KB/s) - ‘data/data.tgz’ saved [166373201/166373201]\n",
            "\n",
            "x yelp_review_polarity_csv/\n",
            "x yelp_review_polarity_csv/train.csv\n",
            "x yelp_review_polarity_csv/readme.txt\n",
            "x yelp_review_polarity_csv/test.csv\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz -O data/data.tgz\n",
        "!tar -xvzf data/data.tgz -C data/\n",
        "!mv data/yelp_review_polarity_csv/* data/\n",
        "!rm -r data/yelp_review_polarity_csv/\n",
        "!rm data/data.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a52521f",
      "metadata": {
        "id": "7a52521f",
        "outputId": "2949d646-dabc-406a-cd5a-ca5b4289c735"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm writing this review to give you a heads up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>All the food is great here. But the best thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0  1  Unfortunately, the frustration of being Dr. Go...\n",
              "1  2  Been going to Dr. Goldberg for over 10 years. ...\n",
              "2  1  I don't know what Dr. Goldberg was like before...\n",
              "3  1  I'm writing this review to give you a heads up...\n",
              "4  2  All the food is great here. But the best thing..."
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "prefix = 'data/'\n",
        "train_df = pd.read_csv(prefix + 'train.csv', header=None)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee8d719",
      "metadata": {
        "id": "dee8d719",
        "outputId": "9ff81e4f-a8e0-4078-f8d3-71659efbd4a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Contrary to other reviews, I have zero complai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Last summer I had an appointment to get new ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Friendly staff, same starbucks fair you get an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>The food is good. Unfortunately the service is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Even when we didn't have a car Filene's Baseme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0  2  Contrary to other reviews, I have zero complai...\n",
              "1  1  Last summer I had an appointment to get new ti...\n",
              "2  2  Friendly staff, same starbucks fair you get an...\n",
              "3  1  The food is good. Unfortunately the service is...\n",
              "4  2  Even when we didn't have a car Filene's Baseme..."
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "eval_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f470fc",
      "metadata": {
        "id": "94f470fc"
      },
      "outputs": [],
      "source": [
        "train_df[0] = (train_df[0] == 2).astype(int)\n",
        "eval_df[0] = (eval_df[0] == 2).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51301f5f",
      "metadata": {
        "id": "51301f5f"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame({\n",
        "    'text': train_df[1].replace(r'\\n', ' ', regex=True),\n",
        "    'label':train_df[0]\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccbb5708",
      "metadata": {
        "id": "ccbb5708",
        "outputId": "cda66972-7807-4ee9-d858-4629bd19c891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0  Unfortunately, the frustration of being Dr. Go...      0\n",
            "1  Been going to Dr. Goldberg for over 10 years. ...      1\n",
            "2  I don't know what Dr. Goldberg was like before...      0\n",
            "3  I'm writing this review to give you a heads up...      0\n",
            "4  All the food is great here. But the best thing...      1\n"
          ]
        }
      ],
      "source": [
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1de1cf",
      "metadata": {
        "id": "0d1de1cf",
        "outputId": "af1c7d3b-67c3-4093-d023-ee57893d216f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0  Contrary to other reviews, I have zero complai...      1\n",
            "1  Last summer I had an appointment to get new ti...      0\n",
            "2  Friendly staff, same starbucks fair you get an...      1\n",
            "3  The food is good. Unfortunately the service is...      0\n",
            "4  Even when we didn't have a car Filene's Baseme...      1\n"
          ]
        }
      ],
      "source": [
        "eval_df = pd.DataFrame({\n",
        "    'text': eval_df[1].replace(r'\\n', ' ', regex=True),\n",
        "    'label':eval_df[0]\n",
        "})\n",
        "\n",
        "print(eval_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57a2dfc4",
      "metadata": {
        "id": "57a2dfc4",
        "outputId": "b346aca0-3639-4478-f194-b26164686404",
        "colab": {
          "referenced_widgets": [
            "0255642007594b06932216c4515298c9",
            "ba5cdc4099464f5493f6357313a060c5",
            "54eba68c38384cc8a8eaba818992cca4",
            "9ffa11e31d204bfca0bf1f1cbadd151d",
            "573abd92c7cf46c1be691ef54a2c59f9"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0255642007594b06932216c4515298c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba5cdc4099464f5493f6357313a060c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54eba68c38384cc8a8eaba818992cca4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ffa11e31d204bfca0bf1f1cbadd151d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "573abd92c7cf46c1be691ef54a2c59f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "# Create a TransformerModel\n",
        "model = ClassificationModel('roberta', 'roberta-base', use_cuda=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e73d7a6",
      "metadata": {
        "id": "5e73d7a6",
        "outputId": "75a00b35-ef50-4da5-cb2d-ca22ebec6c69",
        "colab": {
          "referenced_widgets": [
            "e0428cdbdc1d4de8820d0da108f7b432",
            "31de69ae3d1a481f85cf4657b5c19d9c",
            "c086d8185ec74d8e8ad0c4eb2c79d99c"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/simpletransformers/classification/classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0428cdbdc1d4de8820d0da108f7b432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1120 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/Users/yimam/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31de69ae3d1a481f85cf4657b5c19d9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c086d8185ec74d8e8ad0c4eb2c79d99c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running Epoch 1 of 1:   0%|          | 0/70000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.train_model(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e14ff12",
      "metadata": {
        "id": "0e14ff12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65f1719",
      "metadata": {
        "id": "a65f1719"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cd2df854",
      "metadata": {
        "id": "cd2df854"
      },
      "source": [
        "# Resources\n",
        "1. ![Transformers explained](https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd05cae4",
      "metadata": {
        "id": "bd05cae4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}